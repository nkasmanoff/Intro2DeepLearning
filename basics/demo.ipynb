{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code based on the vid, a dummy data set trained on a numpy neural network made by hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the only dependency\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy and paste the dummy dataset. \n",
    "x = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])  #each line is a datapoint in 3 dimensional vector space, with a binary classification of 1 or 0. \n",
    "                \n",
    "y = np.array([[0],\n",
    "            [1],\n",
    "            [1],\n",
    "            [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build a model. \n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "num_epochs = 60000\n",
    "\n",
    "#initialize weights\n",
    "syn0 = 2*np.random.random((3,4)) - 1 \n",
    "#these weights symbolize the fitting parameters \n",
    "#necessary to determine whether or not the datapoint qualifies as a 1 or 0\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the wieghts and bias used at each node There are 3 nodes, and each value represents some weight (last being bias)\n"
     ]
    }
   ],
   "source": [
    "syn0  \n",
    "print(\"these are the wieghts and bias used at each node\",\n",
    "      \"There are 3 nodes, and each value represents some weight (last being bias)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if this were just a simpler case of logistic regression, there would only be one node into the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 by 4 is the size of the input x.  syn0 corresponds to first hidden layer, and 4 means there 4 nodes in this layer.\n",
    "\n",
    "The next layer is 1, which is multiplied by the 4 nodes in this first layer, and converts it into 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlin(x,deriv = False):\n",
    "    \"\"\"This is the sigmoid function. \n",
    "    \n",
    "    Derivative feature included to help with gradient descent to soon come. \n",
    "    \"\"\"\n",
    "    if deriv :\n",
    "        return x*(1-x)\n",
    "\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.499747786574\n",
      "accuracy:  50.0 %.\n",
      "Error: 0.00836689514599\n",
      "accuracy:  100.0 %.\n",
      "Error: 0.00570403375285\n",
      "accuracy:  100.0 %.\n",
      "Error: 0.00458604315886\n",
      "accuracy:  100.0 %.\n",
      "Error: 0.00393573397119\n",
      "accuracy:  100.0 %.\n",
      "Error: 0.00349851709908\n",
      "accuracy:  100.0 %.\n"
     ]
    }
   ],
   "source": [
    "#Train Model\n",
    "\n",
    "for j in range(num_epochs):\n",
    "    #feed forward through layers 0,1, and 2\n",
    "    k0 = x #input is x.  #layer 0\n",
    "    k1 = nonlin(np.dot(k0, syn0))  #layer 1, \n",
    "    #multiply in the dataset, arrive with a new identify for this data represented in k1. \n",
    "    k2 = nonlin(np.dot(k1, syn1)) #and in this last layer, the values absorbed in k1 are\n",
    "    #multiplied by additional weights here that are then summed to help to determine the class. \n",
    "    \n",
    "    #how much did we miss the target value?\n",
    "    k2_error = y - k2  #error is calcualted like this, as opposed to a binary cross entropy which is pretty helpful in bigger cases. \n",
    "    #how far each of these was from 1. \n",
    "    if (j% 10000) == 0:  #quick sanity check for every 10000 epochs.  The error should drop!\n",
    "        print(\"Error: \" + str(np.mean(np.abs(k2_error))))\n",
    "        print(\"Accuracy: \" , 100*sum(np.around(k2) == y)[0]/len(y), \"%.\")\n",
    "    #in what direction is the target value?  \n",
    "    k2_delta = k2_error*nonlin(k2, deriv=True)  #the direction is\n",
    "    #The sign of the difference between output and error. \n",
    "    #how much did each k1 value contribute to k2 error\n",
    "    k1_error = k2_delta.dot(syn1.T)  #to get k1 go back and calculate error of 1st hidden layer by see how it differs from \n",
    "    #error in k2. \n",
    "    \n",
    "    k1_delta= k1_error * nonlin(k1,deriv=True)\n",
    "    #direction you need to move, error \n",
    "   \n",
    "    #update weights  \n",
    "    syn1 += k1.T.dot(k2_delta) #output layer is affected by the initial\n",
    "    syn0 += k0.T.dot(k1_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.array(k3).reshape(4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
